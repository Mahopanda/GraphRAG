const { GoogleGenAI } = require("@google/genai");
const { LlmCache } = require("./llm-cache");

let ai = null;
let apiKey = null;

// å»¶é²åˆå§‹åŒ–å‡½æ•¸
function initializeAI() {
  if (ai !== null) return ai; // å·²ç¶“åˆå§‹åŒ–éäº†
  
  // ç¢ºä¿ dotenv å·²è¼‰å…¥
  if (!process.env.GEMINI_API_KEY) {
    require("dotenv").config();
  }
  
  apiKey = process.env.GEMINI_API_KEY;
  
  // é©—è­‰APIå¯†é‘°æ ¼å¼
  if (apiKey) {
    if (apiKey.startsWith('AIza')) {
      try {
        ai = new GoogleGenAI({ apiKey });
        console.log("âœ… Gemini API å¯†é‘°æ ¼å¼æ­£ç¢º");
      } catch (error) {
        console.error("âŒ Gemini API å¯†é‘°åˆå§‹åŒ–å¤±æ•—:", error.message);
        ai = false; // æ¨™è¨˜ç‚ºå¤±æ•—
      }
    } else {
      console.error("âŒ Gemini API å¯†é‘°æ ¼å¼ä¸æ­£ç¢ºï¼Œæ‡‰ä»¥ 'AIza' é–‹é ­");
      ai = false; // æ¨™è¨˜ç‚ºå¤±æ•—
    }
  } else {
    console.log("âš ï¸  æœªè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸");
    ai = false; // æ¨™è¨˜ç‚ºå¤±æ•—
  }
  
  return ai;
}

class LlmService {
  constructor(modelName = "gemini-2.5-flash-lite", enableCache = true) {
    this.modelName = modelName;
    this.cache = enableCache ? new LlmCache() : null;
    this._initialized = false;

    // å»¶é²åˆå§‹åŒ–æª¢æŸ¥
    this._checkInitialization();
  }

  _checkInitialization() {
    if (this._initialized) return;
    
    const aiInstance = initializeAI();
    if (aiInstance) {
      console.log(`LLM Service initialized with model: ${this.modelName}`);
      if (this.cache) {
        console.log("ğŸ’¾ LLM å¿«å–å·²å•Ÿç”¨");
        this.cache.cleanExpiredCache();
        const stats = this.cache.getCacheStats();
        console.log(
          `ğŸ“Š å¿«å–çµ±è¨ˆï¼š${stats.count} å€‹æª”æ¡ˆï¼Œ${stats.totalSizeMB} MB`
        );
      }
      this._initialized = true;
    } else {
      console.log(
        "LLM Service initialized without API key - features disabled"
      );
    }
  }

  // å°‡ä»»æ„è¼¸å…¥æ¨™æº–åŒ–æˆ contents[]
  _normalizeContents(input) {
    // 1) å­—ä¸² => å–®è¼ª user è¨Šæ¯
    if (typeof input === "string" && input.trim()) {
      return [{ role: "user", parts: [{ text: input }] }];
    }
    // 2) é™£åˆ— => é€ç­†è½‰ {role, parts:[{text}]}
    if (Array.isArray(input)) {
      return input.map((m) => {
        if (typeof m === "string") {
          return { role: "user", parts: [{ text: m }] };
        }
        // æ”¯æ´ { role, content } æˆ– { role, parts }
        if (m && m.role) {
          if (m.parts && Array.isArray(m.parts)) {
            // å°‡ assistant è§’è‰²è½‰æ›ç‚º model
            const role = m.role === "assistant" ? "model" : m.role;
            return { role, parts: m.parts };
          }
          const text = (m.content ?? "").toString();
          const role = m.role === "assistant" ? "model" : m.role;
          return { role, parts: [{ text }] };
        }
        // Fallback
        return { role: "user", parts: [{ text: JSON.stringify(m) }] };
      });
    }
    // 3) å…¶ä»–ç‰©ä»¶ => stringify ç•¶ä½œä¸€æ®µ user è¨Šæ¯
    return [{ role: "user", parts: [{ text: JSON.stringify(input) }] }];
  }

  async chat(promptOrHistory, timeoutMs = 30000) {
    const aiInstance = initializeAI();
    if (!aiInstance) {
      console.error("âŒ LLM service is not available. Please set GEMINI_API_KEY.");
      console.error("   è«‹æª¢æŸ¥ .env æª”æ¡ˆä¸­æ˜¯å¦æ­£ç¢ºè¨­å®šäº† GEMINI_API_KEY");
      console.error("   æˆ–ä½¿ç”¨ export GEMINI_API_KEY=your_api_key è¨­å®šç’°å¢ƒè®Šæ•¸");
      return "Error: LLM service is not available. Please set GEMINI_API_KEY.";
    }

    const contents = this._normalizeContents(promptOrHistory);

    // ç”Ÿæˆå¿«å–éµ
    const cacheKey = this.cache
      ? this.cache.generateCacheKey(contents, this.modelName)
      : null;

    // æª¢æŸ¥å¿«å–
    if (this.cache && cacheKey) {
      const cachedResponse = this.cache.getCache(cacheKey);
      if (cachedResponse) {
        return cachedResponse;
      }
    }

    // ç°¡å–®çš„ 503/UNAVAILABLE é‡è©¦ï¼ˆå«æŠ–å‹•ï¼‰
    const maxRetries = 4;
    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        // å»ºç«‹ timeout Promise
        const timeoutPromise = new Promise((_, reject) => {
          setTimeout(() => {
            reject(
              new Error(
                `Request timeout after ${timeoutMs}ms. è«‹ç¨å¾Œå†è©¦ï¼Œæˆ–æª¢æŸ¥ç¶²è·¯é€£ç·šã€‚`
              )
            );
          }, timeoutMs);
        });

        // å»ºç«‹ API å‘¼å« Promise
        const apiPromise = aiInstance.models.generateContent({
          model: this.modelName,
          contents,
          // å¯é¸ï¼šåŠ ä¸Š generationConfig ä»¥é™ä½è² è¼‰å³°å€¼
          generationConfig: { temperature: 0.2, topK: 40, topP: 0.95 },
        });

        // ä½¿ç”¨ Promise.race ä¾†å¯¦ç¾ timeout
        const resp = await Promise.race([apiPromise, timeoutPromise]);
        const responseText = resp.text;

        // å„²å­˜åˆ°å¿«å–
        if (this.cache && cacheKey) {
          this.cache.setCache(cacheKey, responseText);
        }

        return responseText;
      } catch (err) {
        const msg = `${err?.status || ""} ${err?.message || err}`;

        // æª¢æŸ¥æ˜¯å¦ç‚º API å¯†é‘°éŒ¯èª¤
        if (msg.includes("API key not valid") || msg.includes("INVALID_ARGUMENT")) {
          console.error(`âŒ Gemini API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ`);
          console.error(`è«‹æª¢æŸ¥ .env æ–‡ä»¶ä¸­çš„ GEMINI_API_KEY æ˜¯å¦æ­£ç¢º`);
          console.error(`éŒ¯èª¤è©³æƒ…: ${err.message}`);
          return "APIå¯†é‘°ç„¡æ•ˆï¼Œç„¡æ³•è™•ç†æ­¤è«‹æ±‚";
        }

        // æª¢æŸ¥æ˜¯å¦ç‚º timeout éŒ¯èª¤
        if (msg.includes("timeout")) {
          console.error(`â° LLM å‘¼å«è¶…æ™‚ (${timeoutMs}ms):`, err.message);
          return `Error: LLM å‘¼å«è¶…æ™‚ã€‚è«‹ç¨å¾Œå†è©¦ï¼Œæˆ–æª¢æŸ¥ç¶²è·¯é€£ç·šã€‚è©³ç´°è³‡è¨Š: ${err.message}`;
        }

        const retriable =
          /UNAVAILABLE|DEADLINE_EXCEEDED|ECONNRESET|ETIMEDOUT/.test(msg);
        if (!retriable || attempt === maxRetries - 1) {
          console.error("Error calling Gemini API:", err);
          return `Error: LLM call failed. Details: ${msg}`;
        }
        const backoff =
          400 * Math.pow(2, attempt) + Math.floor(Math.random() * 200);
        console.log(
          `â³ é‡è©¦ ${attempt + 1}/${maxRetries}ï¼Œç­‰å¾… ${backoff}ms...`
        );
        await new Promise((r) => setTimeout(r, backoff));
      }
    }
  }
}

module.exports = { LlmService };
